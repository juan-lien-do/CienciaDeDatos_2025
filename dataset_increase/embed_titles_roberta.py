from neo4j import GraphDatabase
from sentence_transformers import SentenceTransformer
import math

# Configuraci√≥n de Neo4j
NEO4J_URI = "neo4j://127.0.0.1:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "tu_password"  # CAMBIAR POR TU PASSWORD

# Tama√±o de lote para procesar t√≠tulos (ajusta seg√∫n memoria/CPU)
# Nota: RoBERTa es m√°s pesado que MiniLM, usar lotes m√°s peque√±os
BATCH_SIZE = 128
MODEL_NAME = 'cardiffnlp/twitter-roberta-base-emotion'


def embed_titles_roberta(batch_size=BATCH_SIZE):
    """Genera embeddings para el campo `titulo` usando Twitter-roBERTa-base-emotion y guarda en `embedding_titulo_emotion`.

    Flujo:
    - Lee nodos que tengan `titulo` (streaming desde Neo4j)
    - Procesa en lotes: codifica con Twitter-roBERTa-base-emotion y actualiza en Neo4j
    - Usa `id(n)` para referenciar y actualizar el mismo nodo sin perder otras propiedades
    - Guarda los embeddings en la propiedad `embedding_titulo_emotion`
    
    Ventajas de Twitter-roBERTa-base-emotion:
    - Entrenado espec√≠ficamente en datos de Twitter (textos cortos)
    - Especializado en detecci√≥n de emociones (alegr√≠a, enojo, miedo, sorpresa, etc.)
    - Ideal para predecir viralidad (contenido emocional tiende a ser m√°s viral)
    - Robustez mejorada para textos informales
    - Dimensionalidad: 768 (vs 384 de MiniLM)
    """

    print("üîó Conectando a Neo4j...")
    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))

    # Cargar modelo de embeddings una sola vez (costoso)
    print(f"ü§ñ Cargando modelo Twitter-roBERTa-base-emotion '{MODEL_NAME}'...")
    print("   ÔøΩ Este modelo es m√°s pesado pero espec√≠fico para an√°lisis de emociones")
    print("   üéØ Optimizado para detectar emociones en textos cortos (alegr√≠a, enojo, miedo, etc.)")
    print("   üìà Ideal para predecir viralidad (contenido emocional es m√°s compartible)")
    
    try:
        model = SentenceTransformer(MODEL_NAME)
        print(f"   ‚úÖ Modelo cargado exitosamente (dimensionalidad: {model.get_sentence_embedding_dimension()})")
    except Exception as e:
        print(f"   ‚ùå Error cargando modelo: {e}")
        print("   üí° Instalando modelo autom√°ticamente...")
        # Intentar cargar con auto-download
        model = SentenceTransformer(MODEL_NAME)

    total_processed = 0
    total_updated = 0

    try:
        with driver.session() as session:
            # Verificar si ya existen embeddings de emociones
            print("üîç Verificando embeddings de emociones existentes...")
            check_result = session.run(
                "MATCH (n) WHERE n.embedding_titulo_emotion IS NOT NULL RETURN count(n) AS existing_count"
            )
            existing_count = check_result.single()["existing_count"]
            print(f"   üìä Embeddings de emociones existentes: {existing_count}")
            
            # Ejecutar query que devuelve id(n) y titulo para todos los nodos que tienen titulo
            # pero no tienen embedding_titulo_emotion (evitar reprocessar)
            print("üìä Obteniendo nodos con 'titulo' sin embedding de emociones (streaming)...")
            result = session.run("""
                MATCH (n) 
                WHERE n.titulo IS NOT NULL 
                  AND n.embedding_titulo_emotion IS NULL
                RETURN id(n) AS nid, n.titulo AS titulo
            """)

            batch = []  # lista de tuples (nid, titulo)
            skipped_count = 0

            for record in result:
                nid = record["nid"]
                titulo = record["titulo"]

                # MEJORA: Validaci√≥n m√°s robusta de t√≠tulos nulos/vac√≠os
                # Saltar t√≠tulos nulos o vac√≠os completamente
                if titulo is None or titulo == "":
                    skipped_count += 1
                    continue
                
                # Normalizar a string y limpiar espacios en blanco
                titulo_text = str(titulo).strip()
                
                # Saltar si queda vac√≠o despu√©s de limpiar o es muy corto
                if titulo_text == "" or len(titulo_text) < 3:
                    skipped_count += 1
                    continue

                batch.append((nid, titulo_text))

                # Si alcanzamos el tama√±o de lote, procesamos
                if len(batch) >= batch_size:
                    updated = _process_and_update_batch_roberta(session, model, batch)
                    total_processed += len(batch)
                    total_updated += updated
                    print(f"   ‚úÖ Procesadas {total_processed} (actualizadas: {total_updated}, saltadas: {skipped_count})")
                    batch = []

            # Procesar remanente
            if batch:
                updated = _process_and_update_batch_roberta(session, model, batch)
                total_processed += len(batch)
                total_updated += updated
                print(f"   ‚úÖ Procesadas {total_processed} (actualizadas: {total_updated}, saltadas: {skipped_count})")

    except Exception as e:
        print(f"‚ùå Error general durante el proceso: {e}")
        raise

    finally:
        driver.close()
        print(f"\nüîå Conexi√≥n cerrada.")
        print(f"üìä Resumen del procesamiento:")
        print(f"   üìà Total procesado: {total_processed}")
        print(f"   ‚úÖ Total actualizado: {total_updated}")
        print(f"   ü§ñ Modelo usado: Twitter-roBERTa-base-emotion")
        print(f"   üìè Dimensionalidad: 768")
        print(f"   üòä Especializaci√≥n: Detecci√≥n de emociones para viralidad")


def _process_and_update_batch_roberta(session, model, batch):
    """Codifica una lista de (nid, titulo) con RoBERTa y actualiza los nodos en una sola transacci√≥n.

    Devuelve la cantidad de nodos actualizados exitosamente.
    """
    nids = [item[0] for item in batch]
    titles = [item[1] for item in batch]

    try:
        # Generar embeddings en lote con RoBERTa (devuelve numpy array)
        # RoBERTa puede ser m√°s lento, mostrar progreso
        print(f"      ü§ñ Generando embeddings RoBERTa para {len(titles)} t√≠tulos...")
        embeddings = model.encode(titles, show_progress_bar=True, batch_size=32)  # Batch m√°s peque√±o para RoBERTa
        
        # Convertir embeddings a listas nativas de Python para Neo4j
        rows = []
        for nid, emb in zip(nids, embeddings):
            # emb puede ser numpy array; convertir a lista de floats
            emb_list = emb.tolist() if hasattr(emb, 'tolist') else list(map(float, emb))
            rows.append({"id": int(nid), "embedding": emb_list})

        # Actualizar en una sola query usando UNWIND
        # IMPORTANTE: Usar embedding_titulo_emotion como nombre de propiedad
        update_query = (
            "UNWIND $rows AS row\n"
            "MATCH (n) WHERE id(n) = row.id\n"
            "SET n.embedding_titulo_emotion = row.embedding\n"
            "RETURN count(n) AS updated"
        )

        tx_result = session.run(update_query, rows=rows)
        rec = tx_result.single()
        updated = rec["updated"] if rec else 0
        return updated
        
    except Exception as e:
        print(f"‚ùå Error actualizando lote RoBERTa: {e}")
        # Como fallback intentar actualizar individualmente para encontrar nodos problem√°ticos
        updated = 0
        for i, (nid, titulo) in enumerate(batch):
            try:
                # Generar embedding individual
                embedding = model.encode([titulo], show_progress_bar=False)[0]
                emb_list = embedding.tolist() if hasattr(embedding, 'tolist') else list(map(float, embedding))
                
                session.run(
                    "MATCH (n) WHERE id(n) = $nid SET n.embedding_titulo_emotion = $embedding",
                    nid=int(nid), embedding=emb_list
                )
                updated += 1
            except Exception as inner_e:
                print(f"   ‚ö†Ô∏è Error actualizando nodo {nid} (t√≠tulo: '{titulo[:50]}...'): {inner_e}")
        return updated


def check_roberta_embeddings_stats():
    """
    Funci√≥n auxiliar para verificar estad√≠sticas de los embeddings de emociones generados.
    """
    print("üîç Verificando estad√≠sticas de embeddings de emociones...")
    
    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
    
    try:
        with driver.session() as session:
            # Contar nodos con embeddings de emociones
            result = session.run("""
                MATCH (n) 
                WHERE n.embedding_titulo_emotion IS NOT NULL
                RETURN count(n) AS count_emotion, 
                       size(n.embedding_titulo_emotion[0..1]) AS sample_dimension
                LIMIT 1
            """)
            
            record = result.single()
            if record and record["count_emotion"] > 0:
                count = record["count_emotion"]
                print(f"   ‚úÖ Nodos con embedding_titulo_emotion: {count}")
                
                # Verificar dimensionalidad
                dim_result = session.run("""
                    MATCH (n) 
                    WHERE n.embedding_titulo_emotion IS NOT NULL
                    RETURN size(n.embedding_titulo_emotion) AS dimension
                    LIMIT 1
                """)
                dim_record = dim_result.single()
                if dim_record:
                    dimension = dim_record["dimension"]
                    print(f"   üìè Dimensionalidad verificada: {dimension}")
                
                # Comparar con embeddings MiniLM si existen
                compare_result = session.run("""
                    MATCH (n) 
                    WHERE n.embedding_titulo IS NOT NULL 
                      AND n.embedding_titulo_emotion IS NOT NULL
                    RETURN count(n) AS both_embeddings
                """)
                both_count = compare_result.single()["both_embeddings"]
                print(f"   üîÑ Nodos con ambos embeddings (MiniLM + Emotion): {both_count}")
                
            else:
                print(f"   ‚ùå No se encontraron embeddings de emociones")
                
    except Exception as e:
        print(f"‚ùå Error verificando estad√≠sticas: {e}")
    
    finally:
        driver.close()


if __name__ == '__main__':
    print("üöÄ Iniciando generaci√≥n de embeddings con Twitter-roBERTa-base-emotion")
    print("=" * 75)
    print("üéØ Objetivo: Generar embeddings optimizados para an√°lisis de emociones")
    print("ÔøΩ Modelo: Twitter-roBERTa-base-emotion (768 dimensiones)")
    print("ÔøΩ Especializaci√≥n: Detecci√≥n de emociones para predecir viralidad")
    print(" Campo destino: embedding_titulo_emotion")
    print("‚ö° Batch size reducido por mayor complejidad del modelo")
    print("=" * 75)
    
    # Ajusta BATCH_SIZE si necesitas m√°s/menos paralelismo o memoria
    embed_titles_roberta(batch_size=BATCH_SIZE)
    
    print("\n" + "=" * 75)
    check_roberta_embeddings_stats()
    print("=" * 75)
    print("‚úÖ Proceso completado. Los embeddings de emociones est√°n listos para an√°lisis.")
    print("üòä Tip: Estos embeddings capturan mejor las emociones que pueden predecir viralidad")
    print("üîç Campo generado: embedding_titulo_emotion (768 dimensiones)")