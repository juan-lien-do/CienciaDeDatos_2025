from neo4j import GraphDatabase
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import joblib
import time

# ConfiguraciÃ³n de Neo4j
NEO4J_URI = "neo4j://127.0.0.1:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "tu_password"  # CAMBIAR POR TU PASSWORD

def train_linear_global():
    print("ğŸš€ Iniciando entrenamiento de RegresiÃ³n Lineal Global")
    print("=" * 60)
    
    start_time = time.time()
    
    # 1ï¸âƒ£ ConexiÃ³n a Neo4j
    print("\nğŸ”— Conectando a Neo4j...")
    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
    
    try:
        with driver.session() as session:
            # Consultar noticias de entrenamiento
            print("ğŸ“Š Consultando noticias de entrenamiento...")
            result = session.run("""
                MATCH (n:Noticia)
                WHERE n.subset = 'train'
                RETURN n.embedding AS embedding, n.shares AS shares
            """)
            
            # Recolectar datos
            embeddings = []
            shares = []
            
            print("ğŸ“¥ Recolectando datos...")
            for record in result:
                embedding = record["embedding"]
                share_count = record["shares"]
                
                if embedding is not None and share_count is not None:
                    embeddings.append(embedding)
                    shares.append(share_count)
            
            if not embeddings:
                print("âŒ No se encontraron datos de entrenamiento.")
                return
            
            n_samples = len(embeddings)
            print(f"âœ… Datos recolectados: {n_samples:,} muestras")
            
            # 2ï¸âƒ£ PreparaciÃ³n de los datos
            print("\nğŸ”§ Preparando datos...")
            
            # Convertir embeddings a matriz
            X_train = np.array(embeddings)
            y_train = np.array(shares)
            
            print(f"ğŸ“ Dimensiones X_train: {X_train.shape}")
            print(f"ğŸ“Š EstadÃ­sticas de shares:")
            print(f"   - Min: {np.min(y_train):,}")
            print(f"   - Max: {np.max(y_train):,}")
            print(f"   - Media: {np.mean(y_train):.2f}")
            print(f"   - Mediana: {np.median(y_train):.2f}")
            
            # Escalar features con StandardScaler
            print("âš–ï¸ Aplicando StandardScaler a X_train...")
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            
            # Aplicar transformaciÃ³n logarÃ­tmica al target
            print("ğŸ“ˆ Aplicando transformaciÃ³n logarÃ­tmica a y_train...")
            y_train_log = np.log1p(y_train)
            
            print(f"ğŸ“Š EstadÃ­sticas de y_train_log:")
            print(f"   - Min: {np.min(y_train_log):.4f}")
            print(f"   - Max: {np.max(y_train_log):.4f}")
            print(f"   - Media: {np.mean(y_train_log):.4f}")
            print(f"   - Mediana: {np.median(y_train_log):.4f}")
            
            # 3ï¸âƒ£ Entrenamiento del modelo
            print("\nğŸ§  Entrenando modelo de RegresiÃ³n Lineal...")
            training_start = time.time()
            
            model = LinearRegression()
            model.fit(X_train_scaled, y_train_log)
            
            training_time = time.time() - training_start
            print(f"â±ï¸ Tiempo de entrenamiento: {training_time:.2f} segundos")
            
            # Hacer predicciones en datos de entrenamiento para mÃ©tricas
            print("ğŸ¯ Calculando mÃ©tricas en datos de entrenamiento...")
            y_pred_log = model.predict(X_train_scaled)
            
            # Calcular mÃ©tricas en escala logarÃ­tmica
            r2_log = r2_score(y_train_log, y_pred_log)
            mae_log = mean_absolute_error(y_train_log, y_pred_log)
            rmse_log = np.sqrt(mean_squared_error(y_train_log, y_pred_log))
            
            # Transformar predicciones de vuelta a escala original para mÃ©tricas adicionales
            y_pred_original = np.expm1(y_pred_log)
            mae_original = mean_absolute_error(y_train, y_pred_original)
            rmse_original = np.sqrt(mean_squared_error(y_train, y_pred_original))
            
            # Mostrar mÃ©tricas en consola
            print("\nğŸ“Š MÃ‰TRICAS DEL MODELO:")
            print("=" * 40)
            print(f"ğŸ¯ RÂ² (escala log): {r2_log:.6f}")
            print(f"ğŸ“ MAE (escala log): {mae_log:.6f}")
            print(f"ğŸ“ RMSE (escala log): {rmse_log:.6f}")
            print("=" * 40)
            print("ğŸ“Š MÃ©tricas adicionales (escala original):")
            print(f"ğŸ“ MAE (shares): {mae_original:.2f}")
            print(f"ğŸ“ RMSE (shares): {rmse_original:.2f}")
            
            # 4ï¸âƒ£ Guardar artefactos
            print("\nğŸ’¾ Guardando artefactos...")
            
            # Guardar modelo
            model_filename = 'linear_regression_global.pkl'
            joblib.dump(model, model_filename)
            print(f"âœ… Modelo guardado: {model_filename}")
            
            # Guardar scaler
            scaler_filename = 'scaler.pkl'
            joblib.dump(scaler, scaler_filename)
            print(f"âœ… Scaler guardado: {scaler_filename}")
            
            # Crear DataFrame con mÃ©tricas y guardarlo
            metrics_data = {
                'metric': ['R2_log', 'MAE_log', 'RMSE_log', 'MAE_original', 'RMSE_original'],
                'value': [r2_log, mae_log, rmse_log, mae_original, rmse_original],
                'n_samples': [n_samples] * 5,
                'n_features': [X_train.shape[1]] * 5,
                'training_time_seconds': [training_time] * 5
            }
            
            df_metrics = pd.DataFrame(metrics_data)
            metrics_filename = 'train_metrics_global.csv'
            df_metrics.to_csv(metrics_filename, index=False)
            print(f"âœ… MÃ©tricas guardadas: {metrics_filename}")
            
            # 5ï¸âƒ£ Resumen final
            total_time = time.time() - start_time
            
            print("\n" + "=" * 60)
            print("ğŸ‰ RESUMEN FINAL")
            print("=" * 60)
            print(f"ğŸ“Š NÃºmero de muestras: {n_samples:,}")
            print(f"ğŸ“ Dimensiones de entrada: {X_train.shape}")
            print(f"ğŸ”§ Dimensiones escaladas: {X_train_scaled.shape}")
            print(f"ğŸ“ˆ Target transformado: log1p(shares)")
            print(f"")
            print(f"ğŸ§  Modelo: RegresiÃ³n Lineal")
            print(f"âš–ï¸ Preprocesamiento: StandardScaler")
            print(f"")
            print(f"ğŸ“Š MÃ‰TRICAS PRINCIPALES:")
            print(f"   ğŸ¯ RÂ² (escala log): {r2_log:.6f}")
            print(f"   ğŸ“ MAE (escala log): {mae_log:.6f}")
            print(f"   ğŸ“ RMSE (escala log): {rmse_log:.6f}")
            print(f"")
            print(f"ğŸ“Š MÃ‰TRICAS INTERPRETABLES:")
            print(f"   ğŸ“ MAE (shares): {mae_original:.0f} shares")
            print(f"   ğŸ“ RMSE (shares): {rmse_original:.0f} shares")
            print(f"")
            print(f"â±ï¸ TIEMPOS:")
            print(f"   ğŸ§  Entrenamiento: {training_time:.2f}s")
            print(f"   â° Tiempo total: {total_time:.2f}s")
            print(f"")
            print(f"ğŸ’¾ ARCHIVOS GENERADOS:")
            print(f"   ğŸ“¦ {model_filename}")
            print(f"   âš–ï¸ {scaler_filename}")
            print(f"   ğŸ“Š {metrics_filename}")
            print("=" * 60)
            
            # InformaciÃ³n adicional del modelo
            print(f"\nğŸ” INFORMACIÃ“N ADICIONAL DEL MODELO:")
            print(f"   ğŸ“Š Coeficientes no nulos: {np.count_nonzero(model.coef_)}/{len(model.coef_)}")
            print(f"   ğŸ“ Intercepto: {model.intercept_:.6f}")
            print(f"   ğŸ“ˆ Rango de coeficientes: [{np.min(model.coef_):.6f}, {np.max(model.coef_):.6f}]")
            
            # DistribuciÃ³n de predicciones
            pred_stats = {
                'min_pred': np.min(y_pred_original),
                'max_pred': np.max(y_pred_original),
                'mean_pred': np.mean(y_pred_original),
                'median_pred': np.median(y_pred_original)
            }
            
            print(f"\nğŸ“ˆ DISTRIBUCIÃ“N DE PREDICCIONES (escala original):")
            print(f"   ğŸ“‰ MÃ­n predicciÃ³n: {pred_stats['min_pred']:.0f} shares")
            print(f"   ğŸ“ˆ MÃ¡x predicciÃ³n: {pred_stats['max_pred']:.0f} shares")
            print(f"   ğŸ“Š Media predicciÃ³n: {pred_stats['mean_pred']:.0f} shares")
            print(f"   ğŸ“ Mediana predicciÃ³n: {pred_stats['median_pred']:.0f} shares")
            
            print(f"\nâœ… Entrenamiento completado exitosamente!")
            
    except Exception as e:
        print(f"âŒ Error durante el entrenamiento: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        driver.close()
        print("\nğŸ”Œ ConexiÃ³n a Neo4j cerrada.")

if __name__ == "__main__":
    train_linear_global()